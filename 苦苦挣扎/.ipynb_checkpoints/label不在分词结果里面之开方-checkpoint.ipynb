{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import jieba \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from math import isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = pd.read_excel('数据比较好的.xlsx')\n",
    "Y = txt['标签']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict(Y)\n",
    "stopwords = [line.strip() for line in open('../input/stopword.txt', 'r', encoding='utf-8').readlines()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_des = txt['商品描述'].tolist()\n",
    "X = []\n",
    "with open('分词拿去做word2vect.txt','w',encoding = 'utf8') as file:\n",
    "    for i in range(len(list_des)):\n",
    "        des = list_des[i].replace(' ','')\n",
    "        seg_list = jieba.lcut(des)\n",
    "        word_list = [] \n",
    "        for seg in seg_list:\n",
    "            if seg not in stopwords:\n",
    "                word_list.append(seg)\n",
    "        X.append((' ').join(word_list))\n",
    "        file.write((' ').join(word_list) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt['商品描述'] = pd.Series(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['年', '后', '美国']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut('年后美国')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(columns=['商品描述','标签'])\n",
    "dic = Counter(Y)\n",
    "for i in dic.keys():\n",
    "    data = txt.loc[txt['标签'] == i]\n",
    "    if dic[i] > 100:\n",
    "        frame = pd.concat([frame,data[:100]],axis = 0)\n",
    "        continue\n",
    "    else:\n",
    "        frame = pd.concat([frame,txt.loc[txt['标签'] == i]],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53477, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = frame.reset_index(drop=True)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "fre_matrix = vectorizer.fit_transform(frame['商品描述'])\n",
    "feature_names  = vectorizer.get_feature_names()\n",
    "word_index_dic = vectorizer.vocabulary_\n",
    "length = (fre_matrix.shape)[1]\n",
    "newd = {v:k for k,v in word_index_dic.items()}\n",
    "bag_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<53477x31431 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 503893 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fre_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2262"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(frame['标签']).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for label in Counter(frame['标签']).keys():\n",
    "    if n % 100 == 0:\n",
    "        print(n)\n",
    "    choose = frame.loc[frame['标签'] == label].index\n",
    "    A = fre_matrix[choose].sum(axis=0)\n",
    "    C = np.zeros((1,length),np.int64)\n",
    "    index_list = [] \n",
    "    for i in range(length):\n",
    "        if A[0,i] != 0:\n",
    "            index_list.append(i)\n",
    "            C[0,i] = len(choose) - A[0,i]\n",
    "    choose_1 = frame.loc[frame['标签'] != label].index\n",
    "    B_ = np.zeros((1,length),np.int64)\n",
    "    for index in choose_1:\n",
    "        B_ = fre_matrix[index] + B_\n",
    "    B = np.zeros((1,length),np.int64)\n",
    "    for index in index_list:\n",
    "        B[0,index] = B_[0,index]\n",
    "    D = np.zeros((1,length),np.int64)\n",
    "    for i in range(length):\n",
    "        if B[0,i] != 0:\n",
    "            D[0,i] = len(choose_1) - B[0,i]\n",
    "    AD_BC_2 = (np.array(A)*np.array(D) - np.array(B)*np.array(C))**2\n",
    "    chi2 =  AD_BC_2  / ((np.array(A) + np.array(B))*(np.array(C)+ np.array(D)))\n",
    "    hope_index = {}\n",
    "    for i in range(length):\n",
    "        if isnan(chi2[0,i]) == False:\n",
    "            hope_index[i] = chi2[0,i]\n",
    "    li = sorted(hope_index.items(),key = lambda x:x[1],reverse = True)\n",
    "    for i in range(2):\n",
    "        bag_words.append(newd[li[i][0]])\n",
    "    n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4524 3873\n"
     ]
    }
   ],
   "source": [
    "good_words = list(set(bag_words))\n",
    "print(len(bag_words),len(set(bag_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\scipy\\sparse\\compressed.py:742: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "for row in range((fre_matrix.shape)[0]):\n",
    "    for word in txt['商品描述'][row].split():\n",
    "        if word in good_words:\n",
    "            col = word_index_dic[word]\n",
    "            fre_matrix[row,col] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(fre_matrix,frame['标签'],test_size = 0.2)\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, Y_train)# codingz:utf-8\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(np.mean(y_pred == Y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(fre_matrix,frame['标签'],test_size = 0.2)\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, Y_train)# coding:utf-8\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(np.mean(y_pred == Y_test))\n",
    "#0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超过一百的取前一百条，label不再分词结果里面的。词频 + 开方 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
